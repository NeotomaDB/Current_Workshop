---
title: "A Not so Simple Workflow - SDM Version"
author: "Nora Schlenker, Simon Goring, Socorro Dominguez Vida√±a"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: show
    fig_caption: yes
    keep_md: yes
    self_contained: yes
    theme: readable
    toc: yes
    toc_float: yes
    css: "text.css"
  pdf_document:
    pandoc_args: "-V geometry:vmargin=1in -V geometry:hmargin=1in"
dev: svg
highlight: tango
---

## Building Species Distribution Models from Pollen Data

This RMarkdown document will walk you through the process of:

1. Downloading pollen records from multiple sites -- [Loading Datasets](#loading-datasets)
2. Filtering for specific taxa and taxonomic harmonization -- [Data Filtering](#data-filtering)
3. Filtering and binning for specific time periods
4. Linking to environmental data
5. Performing simple SDMs for different time periods

This work-through is the companion to the Introduction to Neotoma [presentation](https://docs.google.com/presentation/d/1Fwp5yMAvIdgYpiC04xhgV7OQZ-olZIcUiGnLfyLPUt4/edit?usp=sharing).

### Disciplinary Knowledge

Before we start any analysis, we need to recognize that paleoecological data has some important considerations that need to be taken into account. Our "complex" workflow has been simplified to some degree, but, were we to work towards published results, these concepts need to be considered in our work.

#### Taxonomies and Morphotaxa

Pollen "taxa" are identified by the structures of the pollen grains themselves, identified on microscope slides. The level of taxonomic resolution (e.g. species, genera, family) in pollen data varies depending on a number of factors, and, in some cases, does not directly align with standard taxonomies (such as the GBIF Backbone). These taxonomic issues generally fall along several main topics:

* **Taxonomic Resolution**: Many pollen taxa can only be identify to family or genus level due to similarity of pollen at finer taxonomic levels. An additional consideration is that although some pollen that can only be identify to a genus level may be able to be classified to a finer scale based if it is the only species within that genus within a geographic area, however, the pollen may only be identified to the genus level.
* **Analyst Experience**: The technology and skill available to the pollen counter can vary, both as a result of the overall experience and quality of equipment, but also based on where and what kinds of pollen they have identified in the past. An expert in western North American pollen taxa may have skill in this region, but might identify pollen to a lower taxonomic resolution when identifying pollen from Australia.
* **Naming conventions**: Just as analysts have differences in identification, the ways taxa are named varies by analyst and over time. For example, "Poaceae" and "Poaceae undiff." generally refer to the same pollen type but are recorded as different taxa within the database.
* **Uncertainty**: Neotoma uses a [well-documented system for indicating uncertainty](https://open.neotomadb.org/manual/taxonomy-related-tables-1.html#Taxa) in identification. Depending on the research question, we may accept more or less taxonomic uncertainty in our identification.

Due to this, a required step of working with pollen data is to harmonize taxon across sites. The level of resolution of your final taxon harmonization will depend on your research question and location of study.

#### Chronologies and Ages

Chronologies underpin all of our paleoenvironmental analysis and interpretation. Neotoma's data model recognizes the importance of chronologies by providing a data model that supports multiple chronologies per record, and allows new analysts to add their own chronologies to existing records.

Some records in Neotoma are from the 1980s or earlier, and these records may have weak chronologies, relative to modern chronologies. They are built using linear interpolation, the radiocarbon dates are uncalibrated, and often, there is no uncertainty in the age predictions.

Our understanding of the relationship between ^14^C production in the upper atmosphere and its incorporation into organic material has improved over time, resulting in updates to the INTCAL curve. In addition, our chronology construction models have improved, fom simple linear interpolation to more complex Baysian models like BACON.

For this reason, researchers will often undertake chronology re-construction early on in their analysis to ensure there is a standardized approach to building the models.

#### Age Uncertainty

Although each pollen sample is associated with an age (based on the age-depth model/chronology) it is also associated with uncertainty around that age. The amount of uncertainty varies depending on the number and type of dated material (i.e. radiocarbon from macrofossils vs. bulk carbon), the distance of a sample from dated material along the core, and the quality of the overall chronology. Age uncertainty means that pollen samples from two sites with the same estimated age do not neccessarily represent the same moment in time.

 As statistical modelling has improved in the sciences, we have seen more rigorous methods for managing age uncertainty in analysis.

## Load Libraries

For this workshop we only need a few packages. We will download multiple records from Neotoma, filter by taxa and time period, and preform simple species distribution models.

We'll be using the R package `pacman` here, to automatically load and install packages. Note that we also use the package rpaleoclim to download the climate data, but since we have pre-downloaded the climate rasters for you, you will not need that package today.

```{r setup}
pacman::p_load(neotoma2, tidyverse, remotes, terra, sf)
```

## Loading Datasets

We worked through the process for finding and downloading records using `neotoma2` in the [previous workshop](https://open.neotomadb.org/Current_Workshop/simple_workflow.html). For this exercise we will be pulling European pollen records from Neotoma to build species distribution models (SDMs) for taxa at multiple time periods in the past.

To undertake this analysis we need to:

* Define a region of interest
* Download full records (sites, datasets & samples)
* Filter records for data quality (presence of chronologies, taxa, etc.)

### Define Spatial Domain

There are a large number of records in Europe. Downloading this volume of data from Neotoma can take a long time (~2hrs total) and is computationally expensive for the database itself. We have already completed the data download saved it to our data folder. Under the results you can take a look at all the sites we downloaded. As with the previous example, we can use `loc` parameter along with  [WKT](https://arthur-e.github.io/Wicket/sandbox-gmaps3.html) or [geoJSON](http://geojson.io/#map=2/20.0/0.0) objects, and native `sf` objects.

#### Code

```{r geteurope, message = FALSE, eval = TRUE}
europe <-  '{"type": "Polygon",
             "coordinates": [[
              [ -32.13,66.46],
              [-14.09,36.93],
              [30.16,34.71],
              [35.79,69.17],
              [-32.13,66.46]]]}'
europe_sf <- geojsonsf::geojson_sf(europe)

## The following lines of code are commented out because 
#  we've already run it for you to speed up the process. 
#  Downloading large amounts of data can take a long time.
#
# europe_downloads <- neotoma2::get_datasets(loc = europe,
#      datasettype = "pollen",
#      all_data = TRUE) %>%
#   neotoma2::filter(!is.na(age_range_young)) %>% 
#   get_downloads(all_data = TRUE)
# europe_samples <- samples(europe_downloads)

# saveRDS(europe_downloads, "data/europe_downloads.RDS")
# saveRDS(europe_samples, "data/europe_samples.RDS")

europe_downloads <- readRDS("data/europe_downloads.RDS")
europe_samples <- readRDS("data/europe_samples.RDS")

```

#### Sites Map

```{r geteuropeshow, eval=TRUE, echo = FALSE}

neotoma2::plotLeaflet(europe_downloads) %>% 
  leaflet::addPolygons(map = ., 
                       data = europe_sf, 
                       color = "green")

```

### Data table

```{r downloadsCode, echo = FALSE}

head(europe_samples, n = 10) %>%
  dplyr::select(age,
    variablename,
    ecologicalgroup,
    value,
    units,
    sitename,
    lat,
    long) %>%
  DT::datatable(data = ., 
                options = list(scrollX = "100%", dom = 't'))
```

### Data Filtering

#### Sample Filtering

When we look at pollen data we are looking at counts of pollen data, from a slide, for a particular analysis unit. Along with pollen there can also be measurements of charcoal, records of algal cycts, and other lab-based measurements. In addition, we often look only at terrestrial pollen types, since they generally reflect regional vegetation, as opposed to the pollen of aquatic types that would represent local site conditions.

Even though the datasets are pollen datasets, the `europe_samples` `data.frame` contains data for a number of different measured elements, including things like mandibles, scales and sporangia. In addition, these elements are measured using `r length(unique(europe_samples$units))` different measurement units (`unique(europe_samples$units)`) across `r length(unique(europe_samples$ecologicalgroup))` ecological groups (`unique(europe_samples$ecologicalgroup)`) including diatoms, trees and shrubs, rotifers and insects.

##### Standard Units and Elements

We often use pollen proportions in our analysis, and for this we need to find out how many total pollen grains were counted in each sample.  We also want to make sure we're looking at a common set of taxa across all sites. In this case we will filter for trees and shrubs (ecological group `TRSH`) and upland herbs (ecological group `UPHE`). We will also look for pollen (element type `pollen`) that is measured using the Number of Identified Specimens (units `NISP`).

This makes the filtering rather straightforward:

```{r cutsamples}
europe_cleaner <- europe_samples %>%
  filter(units == 'NISP' & 
         elementtype == 'pollen' &
         (ecologicalgroup %in% c('TRSH', 'UPHE')))
```

This initial filtering removes about `r round(nrow(europe_samples) - nrow(europe_cleaner), -3)` rows from our original dataset.

##### Standardizing Taxa

For the purposes of this analysis we will only be focusing on building models for *Corylus*, *Fagus* and *Picea*.  

Before we can start looking at our focal species we need to do some work with our sample table so that we have all the information we want. We need to do three things at this step: filtering the data to only include our focal taxa, doing taxon harmonization on our focal taxa, and calculating the pollen percent for each focal taxa for each pollen sample.

*Note:* Our taxon harmonization here is very simple and more thought should be put into taxon harmonization.

Our first task is to make a table that we will join with our samples table that tells us the total number of pollen per sample which we will use in our pollen percentage calculations. There are many decisions you can make at this step depending on your research question but here we are going to calculate pollen percent based on the total number of trees, shrubs, and herbaceous groups (ecologicalgroup = TRSH and UPHE). This is common for may studies that focus on these ecological groups but know that you can choose other combinations and this will effect how you interpret your results.  

Then we can combine taxon filtering and harmonization and pollen percent calculation all in one segment of code. Here we are selecting the taxa *Fagus*, *Picea*, and *Corylus* and harmonizing all variations of those taxa to the genus level. We can use the code below to look at the diversity of identifiers for these three taxa:

```r
europe_cleaner %>%
  filter(stringr::str_detect(variablename, "Fagus|Corylus|Picea")) %>%
  select(variablename) %>% distinct()
```

For our purposes it will be enough to simply standardize all taxa idenfied as some form of *Picea* to *Picea*, and the same for the *Corylus* and *Fagus* types.  This then lets us right some fairly clean code as follows:

###### Code

```{r replacetaxa}
europe_cleaner <- europe_cleaner %>%
  mutate(variablename = replace(variablename, 
                                stringr::str_detect(variablename, "Fagus"),
                                "Fagus"),
         variablename = replace(variablename,
                                stringr::str_detect(variablename, "Picea"),
                                "Picea"),
         variablename = replace(variablename,
                                stringr::str_detect(variablename,
                                "Corylus"),
                                "Corylus")) %>%
    group_by(datasetid, age, variablename, units, ecologicalgroup, sitename, lat, long) %>%
    summarise(value = sum(value)) %>% as.data.frame()
```

We have to `summarise` at the end to make sure that counts of taxon name variants within a single sample get lumped together properly.  Once we've run this code, we can test out the earlier code block to see if we are now down to three distinct taxa (and we ought to be).

**Note**: We're using `as.data.frame()` here to speed up operations below. Leaving this object as a `grouped_df` seem to seriously impact performance.

##### Age Filtering

The age ranges for these records may be broad. Some European records go back over 100,000 years before present, and some samples (and datasets) appear to have no chronologies. We can check the ages using the columns `age`, `ageolder` and `ageyounger`. Note that many chronologies have been entered without uncertainty measures, in which case `ageolder` and `ageyounger` would be unreported. Otherwise these values represent ¬±1 standard deviation.

We will be building our SDMs for three critical time periods in the time since the last glaciation:

| time period | age range (ybp) | label |
| ----------- | --------------- | ----- |
| Modern      |  -76 - 150      | `modern` |
| Younger Dryas | 11,700 - 12,900 | `yd` |
| Last Glacial Maximum | > 21,000 | `lgm` |

To prepare the data for analysis we will create a new column using `mutate`, based on our time bins, and filter out any records that are not within our defined periods of study:

```{r agecleaning}
europe_ready <- europe_cleaner %>%
  mutate(timebins = case_when(age >= -72 & age <= 150 ~ "Modern",
                              age >= 11700 & age <= 12900 ~ "YD", 
                              age >= 20000 & age <= 22000 ~ "LGM",
                              .default = NA)) %>%
    filter(!is.na(timebins)) %>%
  as.data.frame()
```

Our data is now ready for further analysis. We've cleaned the taxonomy, ensured all data are of a similar type and measured with similar units, and we've made sure that our time bins are clearly defined.

*Note:* We do not attempt to update age-depth models and we filter out all samples that do not have age estimates when some of them may be able to be included under closer inspection. Additionally, we do not take into account time uncertainty which is another aspect that should be considered when filtering by time.

#### Calculating Pollen Sums & Percentages

From here we need to calculate the pollen sum for each sample in our set of samples. This means that we will get the total number of pollen grains counted for e.g., Kansj√∂n at depth 445cm in the core. We can calculate both the pollen sum and the proportion at the same time by using `group_by()` and `ungroup()` to first sum the `value` fields (the counts) and then calculate the proportion from our new `totalpollen` field:

```{r}
europe_subset <- europe_ready %>%
  group_by(datasetid, age, sitename, lat, long, timebins) %>%
  mutate(totalpollen = sum(value)) %>%
  ungroup() %>%
  mutate(polprop = round(value / totalpollen, 2)) %>%
  as.data.frame()
```

#### Results

```{r filtertaxaShow, eval = TRUE, message = FALSE, echo = FALSE}
europe_subset[1:10,] %>% 
  DT::datatable(data = ., 
                options = list(scrollX = "100%", dom = 't'))

ggplot(europe_subset, aes(age)) + geom_histogram() + ylab("Count of Samples") + xlab("Age (years before present)") + theme_minimal()
```

## Loading Climate Data {.tabset}

There is no climate data associated with pollen data downloaded from Neotoma but you can utilize climate data that is available online to intersect with the locations of pollen samples. For this we will be using climate data from [Paleoclim](http://www.paleoclim.org/) which compiles climate data from present to the Pliocene from various sources. We will be using their modern and LGM climate data from CHELSA and Younger Dryas climate data from [Fordham  et al., 2017](https://nsojournals.onlinelibrary.wiley.com/doi/full/10.1111/ecog.03031). There are a few options for choosing climate reconstructions for use with paleodata:

### Code

```{r downloadclims, message = FALSE, eval = TRUE}
# europe_clim_mod <- paleoclim("cur", "5m", region = terra::ext(europe_sf))
# europe_clim_yd <- paleoclim("yds", "5m", region = terra::ext(europe_sf))
# europe_clim_lgm <- paleoclim("lgm", "5m", region = terra::ext(europe_sf))
# 
# saveRDS(europe_clim_mod, "data/europe_clim_mod.RDS")
# saveRDS(europe_clim_yd, "data/europe_clim_yd.RDS")
# saveRDS(europe_clim_lgm, "data/europe_clim_lgm.RDS")

europe_clim_mod <- readRDS("data/europe_clim_mod.RDS")
europe_clim_yd <- readRDS("data/europe_clim_yd.RDS")
europe_clim_lgm <- readRDS("data/europe_clim_lgm.RDS")

```

### Results

```{r downloadclimsShow, echo = FALSE, message = FALSE, eval = TRUE}
plot(europe_clim_mod[["bio_1"]]/10, main = "Modern Mean Annual Temp, Europe")

```

### Younger Dryas

```{r downloadclimsShow2, echo = FALSE, message = FALSE, eval = TRUE}
plot(europe_clim_yd[["bio_1"]]/10, main = "Younger Dryas Mean Annual Temp, Europe")

```

### Last Glacial Maximum

```{r downloadclimsShow3, echo = FALSE, message = FALSE, eval = TRUE}
plot(europe_clim_lgm[["bio_1"]]/10, main = "LGM Mean Annual Temp, Europe")

```

## Species Distribution Models

### Extracting environmental varliables {.tabset}

#### Extracting Environmental Variables

```{r extractclims, message = FALSE, eval = TRUE}
#First lets save the projection information from our climate data to use later when creating our species points data
proj_data <- crs(europe_clim_mod)

extract_clims <- function(taxa_data, clim_data, time_text, taxa_text, projection = proj_data) {
  time_cut <- dplyr::filter(taxa_data, timebins == time_text)
  time_sf <- st_as_sf(time_cut, coords = c("long", "lat"), crs = projection)
  time_sf_vect <- vect(time_sf$geometry)
  time_sf_clims <- terra::extract(clim_data, time_sf_vect)
  time_sf_full <- cbind(time_sf, time_sf_clims)
  dplyr::filter(time_sf_full, variablename == taxa_text)

}

## Last Glacial Maximum 
taxa_lgm <- st_as_sf(taxa_lgm, coords = c("long", "lat"), crs = proj_data)
taxa_lgm_vect <- vect(taxa_lgm$geometry)
taxa_lgm_clims <- terra::extract(europe_clim_lgm, taxa_lgm_vect)
taxa_lgm <- cbind(taxa_lgm, taxa_lgm_clims)
corylus_lgm <- filter(taxa_lgm, variablename == "Corylus")
fagus_lgm <- filter(taxa_lgm, variablename == "Fagus")
picea_lgm <- filter(taxa_lgm, variablename == "Picea")
```

#### Corylus

```{r extractclimsshow1, echo = FALSE, message = FALSE, eval = TRUE, warnings = FALSE}

rbind(corylus_mod, corylus_yd, corylus_lgm) %>%
  select(timebins, pollen_percent, bio_1, bio_12, bio_4, bio_15, geometry) %>%
  pivot_longer(-c(timebins, pollen_percent, geometry)) %>%
  mutate(timebins_fact = factor(timebins, levels = c("Modern", "YD", "LGM"))) %>%
  ggplot(aes(value, pollen_percent)) + geom_point() +
  facet_grid(timebins_fact~name, scales = "free", switch = "x") +
  xlab("") +
  ylab("Pollen Percent")+
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45))

```

#### Fagus

```{r extractclimsshow2, echo = FALSE, message = FALSE, eval = TRUE, warning = FALSE}

rbind(fagus_mod, fagus_yd, fagus_lgm) %>%
  select(timebins, pollen_percent, bio_1, bio_12, bio_4, bio_15, geometry) %>%
  pivot_longer(-c(timebins, pollen_percent, geometry)) %>%
  mutate(timebins_fact = factor(timebins, levels = c("Modern", "YD", "LGM"))) %>%
  ggplot(aes(value, pollen_percent)) + geom_point() +
  facet_grid(timebins_fact~name, scales = "free", switch = "x") +
  xlab("") +
  ylab("Pollen Percent")+
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45))

```

#### Picea

```{r extractclimsshow3, echo = FALSE, message = FALSE, eval = TRUE, warning = FALSE}

rbind(picea_mod, picea_yd, picea_lgm) %>%
  select(timebins, pollen_percent, bio_1, bio_12, bio_4, bio_15, geometry) %>%
  pivot_longer(-c(timebins, pollen_percent, geometry)) %>%
  mutate(timebins_fact = factor(timebins, levels = c("Modern", "YD", "LGM"))) %>%
  ggplot(aes(value, pollen_percent)) + geom_point() +
  facet_grid(timebins_fact~name, scales = "free", switch = "x") +
  xlab("") +
  ylab("Pollen Percent")+
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45))

```

### Predicting Species Distributions

Next we are going to set up the species distribution models

#### Corylus {.tabset}

##### Code

```{r corylussdm, message = FALSE, eval = TRUE}
corylus_mod_glm <- glm(pollen_percent ~ bio_1 + bio_12, data = corylus_mod, family = gaussian)
corylus_mod_glm_predict <- predict(c(europe_clim_mod[["bio_1"]], europe_clim_mod[["bio_12"]]), corylus_mod_glm)

corylus_yd_glm <- glm(pollen_percent ~ bio_1 + bio_12, data = corylus_yd, family = gaussian)
corylus_yd_glm_predict <- predict(c(europe_clim_yd[["bio_1"]], europe_clim_yd[["bio_12"]]), corylus_yd_glm)

corylus_lgm_glm <- glm(pollen_percent ~ bio_1 + bio_12, data = corylus_lgm, family = gaussian)
corylus_lgm_glm_predict <- predict(c(europe_clim_lgm[["bio_1"]], europe_clim_lgm[["bio_12"]]), corylus_lgm_glm)

# Using Presence Only data
corylus_mod_glm_pres <- glm(presence ~ bio_1 + bio_12, data = corylus_mod, family = binomial)
corylus_mod_glm_pres_predict <- predict(c(europe_clim_mod[["bio_1"]], europe_clim_mod[["bio_12"]]), corylus_mod_glm_pres)

corylus_yd_glm_pres <- glm(presence ~ bio_1 + bio_12, data = corylus_yd, family = binomial)
corylus_yd_glm_pres_predict <- predict(c(europe_clim_yd[["bio_1"]], europe_clim_yd[["bio_12"]]), corylus_yd_glm_pres)

corylus_lgm_glm_pres <- glm(presence ~ bio_1 + bio_12, data = corylus_lgm, family = binomial)
corylus_lgm_glm_pres_predict <- predict(c(europe_clim_lgm[["bio_1"]], europe_clim_lgm[["bio_12"]]), corylus_lgm_glm_pres)

```

##### Results
```{r corylussdmshow, echo = FALSE, message = FALSE, eval = TRUE}
par(mfrow = c(2,3))

plot(corylus_mod_glm_predict, main = "Predicted Corylus Pollen Percent, Modern")
plot(corylus_yd_glm_predict, main = "Predicted Corylus Pollen Percent, Younger Dryas")
plot(corylus_lgm_glm_predict, main = "Predicted Corylus Pollen Percent, LGM")

# Using Presence Only data
plot(corylus_mod_glm_pres_predict, main = "Predicted Corylus Presence, Modern")
plot(corylus_yd_glm_pres_predict, main = "Predicted Corylus Presence, Younger Dryas")
plot(corylus_lgm_glm_pres_predict, main = "Predicted Corylus Presence, LGM")

```

#### Fagus {.tabset}

##### Code
```{r fagussdm, message = FALSE, eval = TRUE}
fagus_mod_glm <- glm(pollen_percent ~ bio_1 + bio_12, data = fagus_mod)
fagus_mod_glm_predict <- predict(c(europe_clim_mod[["bio_1"]], europe_clim_mod[["bio_12"]]), fagus_mod_glm)

fagus_yd_glm <- glm(pollen_percent ~ bio_1 + bio_12, data = fagus_yd)
fagus_yd_glm_predict <- predict(c(europe_clim_yd[["bio_1"]], europe_clim_yd[["bio_12"]]), fagus_yd_glm)

fagus_lgm_glm <- glm(pollen_percent ~ bio_1 + bio_12, data = fagus_lgm)
fagus_lgm_glm_predict <- predict(c(europe_clim_lgm[["bio_1"]], europe_clim_lgm[["bio_12"]]), fagus_lgm_glm)

# Using Presence Only data
fagus_mod_glm_pres <- glm(presence ~ bio_1 + bio_12, data = fagus_mod)
fagus_mod_glm_pres_predict <- predict(c(europe_clim_mod[["bio_1"]], europe_clim_mod[["bio_12"]]), fagus_mod_glm_pres)

fagus_yd_glm_pres <- glm(presence ~ bio_1 + bio_12, data = fagus_yd)
fagus_yd_glm_pres_predict <- predict(c(europe_clim_yd[["bio_1"]], europe_clim_yd[["bio_12"]]), fagus_yd_glm_pres)

fagus_lgm_glm_pres <- glm(presence ~ bio_1 + bio_12, data = fagus_lgm)
fagus_lgm_glm_pres_predict <- predict(c(europe_clim_lgm[["bio_1"]], europe_clim_lgm[["bio_12"]]), fagus_lgm_glm_pres)

```

##### Results
```{r fagussdmshow, echo = FALSE, message = FALSE, eval = TRUE}
par(mfrow = c(2,3))

plot(fagus_mod_glm_predict, main = "Predicted Fagus Pollen Percentage, Modern")
plot(fagus_yd_glm_predict, main = "Predicted Fagus Pollen Percentage, Younger Dryas")
plot(fagus_lgm_glm_predict, main = "Predicted Fagus Pollen Percentage, LGM")

# Using Presence Only data
plot(fagus_mod_glm_pres_predict, main = "Predicted Fagus Presence, Modern")
plot(fagus_yd_glm_pres_predict, main = "Predicted Fagus Presence, Younger Dryas")
plot(fagus_lgm_glm_pres_predict, main = "Predicted Fagus Presence, LGM")

```

#### Picea {.tabset}

##### Code
```{r piceasdm, message = FALSE, eval = TRUE}
picea_mod_glm <- glm(pollen_percent ~ bio_1 + bio_12, data = picea_mod)
picea_mod_glm_predict <- predict(c(europe_clim_mod[["bio_1"]], europe_clim_mod[["bio_12"]]), picea_mod_glm)

picea_yd_glm <- glm(pollen_percent ~ bio_1 + bio_12, data = picea_yd)
picea_yd_glm_predict <- predict(c(europe_clim_yd[["bio_1"]], europe_clim_yd[["bio_12"]]), picea_yd_glm)

picea_lgm_glm <- glm(pollen_percent ~ bio_1 + bio_12, data = picea_lgm)
picea_lgm_glm_predict <- predict(c(europe_clim_lgm[["bio_1"]], europe_clim_lgm[["bio_12"]]), picea_lgm_glm)

# Using Presence Only data
picea_mod_glm_pres <- glm(presence ~ bio_1 + bio_12, data = picea_mod)
picea_mod_glm_pres_predict <- predict(c(europe_clim_mod[["bio_1"]], europe_clim_mod[["bio_12"]]), picea_mod_glm_pres)

picea_yd_glm_pres <- glm(presence ~ bio_1 + bio_12, data = picea_yd)
picea_yd_glm_pres_predict <- predict(c(europe_clim_yd[["bio_1"]], europe_clim_yd[["bio_12"]]), picea_yd_glm_pres)

picea_lgm_glm_pres <- glm(presence ~ bio_1 + bio_12, data = picea_lgm)
picea_lgm_glm_pres_predict <- predict(c(europe_clim_lgm[["bio_1"]], europe_clim_lgm[["bio_12"]]), picea_lgm_glm_pres)

```

##### Results
```{r piceasdmshow, echo = FALSE, message = FALSE, eval = TRUE}
par(mfrow = c(2,3))

plot(picea_mod_glm_predict, main = "Predicted picea Pollen Percentage, Modern")
plot(picea_yd_glm_predict, main = "Predicted picea Pollen Percentage, Younger Dryas")
plot(picea_lgm_glm_predict, main = "Predicted picea Pollen Percentage, LGM")

# Using Presence Only data
plot(picea_mod_glm_pres_predict, main = "Predicted Picea Presence, Modern")
plot(picea_yd_glm_pres_predict, main = "Predicted Picea Presence, Younger Dryas")
plot(picea_lgm_glm_pres_predict, main = "Predicted Picea Presence, LGM")

```

####
###

## Exercise

Now that we have walked through getting your data into a format that can used for Species Distribution Models you can now answer a number of questions, such as:

* How do SDMs created using modern pollen and hindcast compare to models created from data of that time period?
* Do occurrences of taxa occupy different portions of climate space through time? 
* Many more!

Now it is your turn to come up with a question that can be answered by our data and create code to answer your question. When you are finished you can share your results by pasting a screenshot of a figure to our [presentation](https://docs.google.com/presentation/d/1Fwp5yMAvIdgYpiC04xhgV7OQZ-olZIcUiGnLfyLPUt4/edit?usp=sharing).

## Summary

From this notebook we have learned how to:

1. Downloading pollen records from multiple sites
2. Filtering for specific taxa and taxonomic harmonization
3. Filtering and binning for specific time periods
4. Linking to environmental data
5. Performing simple SDMs for different time periods

This approach is very simple workflow for taking records from many sites and combining them into species distribution models to compare species distributions at different periods of time.

### Other Helpful R Packages

These packages may be helpful to your for future paleoecological analysis:

* [RFossilpoll](https://hope-uib-bio.github.io/FOSSILPOL-website/) - package to help streamline the data downloading and filtering of paleoecological data from Neotoma and other resources

* [R-Ratepol](https://hope-uib-bio.github.io/R-Ratepol-package/) - package to calculate rate of change from community time series data

* [rpaleoclim](http://www.paleoclim.org/) - package to facilitate direct download of high resolution paleo-climate data
