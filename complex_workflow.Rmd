---
title: "A Not so Simple Workflow - SDM Version"
author: "Nora Schlenker, Simon Goring, Socorro Dominguez Vida√±a"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: show
    fig_caption: yes
    keep_md: yes
    self_contained: yes
    theme: readable
    toc: yes
    toc_float: yes
    css: "text.css"
  pdf_document:
    pandoc_args: "-V geometry:vmargin=1in -V geometry:hmargin=1in"
dev: svg
highlight: tango
---

## Building New Chronologies

This RMarkdown document will walk you through the process of:

1.  Downloading pollen records from multiple sites
2.  Filtering for specific taxa and taxonomic harmonization
3.  Filtering and binning for specific time periods
4.  Linking to environmental data
5.  Performing simple SDMs for different time periods

## Load Libraries

For this workshop element we only need quite a few packages. We'll be loading multiple records from Neotoma, filtering by taxa and time periods, and preforming simple species distribution models.

We'll be using the R package `pacman` here, to automatically load and install packages. Note that we also use the package rpaleoclim to download the climate data, but since we have pre-downloaded the climate rasters for you, you will not need that package today. 

```{r setup}
pacman::p_load(neotoma2, dplyr, ggplot2, remotes, terra, sf)
```

## Loading Datasets 

We worked through the process for finding and downloading records using `neotoma2` in the [previous workshop](https://open.neotomadb.org/Current_Workshop/simple_workflow.html). For this exercise we will be pulling pollen records from all of Europe to contstruct species distribution models for select species for different time periods. The following code defines our region of interest (a simple polygon of Europe) and downloads the sites, dataset, and downloads for all pollen records that are not missing an age depth model. This is the same workflow as the simple workflow we completed in the morning session but condensed to a few lines of code. Downloading this volume of data from Neotoma can take a long time and is computationally expensive for the database itself so we have already completed the data download and here you will read in the data from our data folder.Under the results you can take a look at all the sites we downloaded. 

#### Code 
```{r geteurope, message = FALSE, eval = TRUE}
europe <-  '{"type": "Polygon",
"coordinates": [[
 [ -32.13,66.46],
 [-14.09,36.93],
 [30.16,34.71],
 [35.79,69.17],
 [-32.13,66.46]]]}'
europe_sf <- geojsonsf::geojson_sf(europe)

## The following lines of code are commented out because we've already run it for you to speed up the process. 
# Downloading large amounts of data can take a long time.
# europe_sites <- neotoma2::get_sites(loc = europe, datasettype = "pollen", all_data = TRUE)
# europe_datasets <- neotoma2::get_datasets(loc = europe, datasettype = "pollen", all_data = TRUE)
# europe_records <- europe_datasets %>% 
#   neotoma2::filter(!is.na(age_range_young))
# europe_downloads <- europe_records %>% get_downloads(all_data = TRUE)
# europe_samples <- samples(europe_downloads)
# 
# saveRDS(europe_sites, "data/europe_sites.RDS")
# saveRDS(europe_datasets, "data/europe_datasets.RDS")
# saveRDS(europe_downloads, "data/europe_downloads.RDS")
# saveRDS(europe_samples, "data/europe_samples.RDS")

europe_sites <- readRDS("data/europe_sites.RDS")
europe_datasets <- readRDS("data/europe_datasets.RDS")
europe_downloads <- readRDS("data/europe_downloads.RDS")
europe_samples <- readRDS("data/europe_samples.RDS")

```

#### Sites Map
```{r geteuropeshow, eval=TRUE, echo = FALSE}

neotoma2::plotLeaflet(europe_sites) %>% 
  leaflet::addPolygons(map = ., 
                       data = europe_sf, 
                       color = "green")

```

#### Data table

```{r downloadsCode, echo = FALSE}
europe_samples[1:10,] %>% dplyr::select(age, variablename, ecologicalgroup, value, units, sitename, lat, long) %>% 
  DT::datatable(data = ., 
                options = list(scrollX = "100%", dom = 't'))
```

### Data Filtering 
Taxon filtering and harmonization, pollen percent calculations, and data exploration 

Before we can start looking at our focal species we need to do some work with our sample table so that we have all the information we want. We need to do three things at this step: filtering the data to only include our focal taxa, doing taxon harmonization on our focal taxa, and calculating the pollen percent for each focal taxa for each pollen sample. 

Our first task is to make a table that we will join with our samples table that tells us the total number of pollen per sample which we will use in our pollen percentage calculations. There are many decisions you can make at this step depending on your research question but here we are going to calculate pollen percent based on the total number of trees, shrubs, and herbaceous groups (ecologicalgroup = TRSH and UPHE). This is common for may studies that focus on these ecological groups but know that you can choose other combinations and this will effect how you interpret your results.  

Then we can combine taxon filtering and harmonization and pollen percent calculation all in one segment of code. Here we are selecting the taxa *Fagus*, *Picea*, and *Corylus* and harmonizing all variations of those taxa to the genus level. 

#### Code
```{r filtertaxa, message = FALSE, eval = TRUE}
poll_total <- europe_samples %>%
  filter(ecologicalgroup == "TRSH" | ecologicalgroup == "UPHE") %>% 
  group_by(datasetid, age) %>%
  summarise(totalpollen = sum(value)) %>%
  ungroup() 

europe_subset <- europe_samples %>%
  inner_join(poll_total, by = c("datasetid" = "datasetid", "age" = "age")) %>%
  mutate(poll_perc = round(value/totalpollen*100, 2)) %>%
  #filter to only taxa with the genera of our focal species
  filter(stringr::str_detect(variablename, "Fagus*") | 
           stringr::str_detect(variablename, "Picea*") | 
           stringr::str_detect(variablename, "Corylus*")) %>%
  #limiting the age to the range of ages we are interesting in. Here -74 is present since "radiocarbon years before present" starts at 1950
  filter(age >= -74 & age <= 23000) %>% 
  #rename our focal species to just their genera
  mutate(variablename = replace(variablename, stringr::str_detect(variablename, "Fagus*"), "Fagus"), 
         variablename = replace(variablename, stringr::str_detect(variablename, "Picea*"), "Picea"), 
         variablename = replace(variablename, stringr::str_detect(variablename, "Corylus*"), "Corylus")) %>%
  #group taxa of the same dataset and age to combine all renamed versions of taxa to get one pollen percent value for a harmonized record 
  group_by(datasetid, age, variablename, units, ecologicalgroup, sitename, lat, long) %>%
  summarise(pollen_percent = sum(poll_perc)) %>%
  mutate(presence = case_when(pollen_percent > 1 ~ 1,
                              .default = 0))
```

#### Results
```{r filtertaxaShow, eval = TRUE, message = FALSE, echo = FALSE}
europe_subset[1:10,] %>% 
  DT::datatable(data = ., 
                options = list(scrollX = "100%", dom = 't'))

ggplot(europe_subset, aes(age)) + geom_histogram() + ylab("Count of Samples") + xlab("Age (years before present)") + theme_minimal()
```

### Bin and filter data by time 
Now that we have a dataset with our three focal taxa we now want to filter these taxa into time periods of interest. For this exercise we will be looking at modern samples (1950 to present), the Younger Drays (12.9 to 11.7 thousand years ago), and the Last Glacial Maximum (LGM; 21 thousand years ago). 

#### Code
```{r binbyage, message = FALSE, eval = TRUE}
europe_binned <- europe_subset %>% 
  mutate(timebins = case_when(age <= 0 ~ "Modern",
                             age >= 11700 & age <= 12900 ~ "YD", 
                             age >= 20000 & age <= 22000 ~ "LGM",
                             .default = NA)) %>%
  filter(!is.na(timebins))
```

#### Results
```{r binbyageShow, eval = TRUE, message = FALSE, echo = FALSE}
europe_binned %>% 
  mutate(timebins = factor(timebins, levels = c("Modern", "YD", "LGM"))) %>%
  ggplot(aes(timebins)) + geom_bar(stat = "count") + 
  geom_text(stat='count', aes(label=after_stat(count)), vjust=-.5) +
  facet_wrap(~variablename, ncol = 3) +
  ylab("Count of Samples") + xlab("Time Bins") + theme_minimal()

```

## Loading Climate Data


#### Code
```{r downloadclims, message = FALSE, eval = TRUE}
# europe_clim_mod <- paleoclim("cur", "5m", region = terra::ext(europe_sf))
# europe_clim_yd <- paleoclim("yds", "5m", region = terra::ext(europe_sf))
# europe_clim_lgm <- paleoclim("lgm", "5m", region = terra::ext(europe_sf))
# 
# saveRDS(europe_clim_mod, "data/europe_clim_mod.RDS")
# saveRDS(europe_clim_yd, "data/europe_clim_yd.RDS")
# saveRDS(europe_clim_lgm, "data/europe_clim_lgm.RDS")

europe_clim_mod <- readRDS("data/europe_clim_mod.RDS")
europe_clim_yd <- readRDS("data/europe_clim_yd.RDS")
europe_clim_lgm <- readRDS("data/europe_clim_lgm.RDS")

```
#### Results
```{r downloadclimsShow, echo = FALSE, message = FALSE, eval = TRUE}
plot(europe_clim_mod[["bio_1"]]/10, main = "Modern Mean Annual Temp, Europe")
plot(europe_clim_yd[["bio_1"]]/10, main = "Younger Dryas Mean Annual Temp, Europe")
plot(europe_clim_lgm[["bio_1"]]/10, main = "LGM Mean Annual Temp, Europe")

```

## Species Distribution Models 

Now that we have our taxa data and our climate data ready to go we will now extract climate data for each of the samples, create SDMs, and predict species distributions for all three taxa in all three time periods.  

#### Extracting environmental varliables
```{r extractclims, message = FALSE, eval = TRUE}
#First lets save the projection information from our climate data to use later when creating our species points data
proj_data <- crs(europe_clim_mod)

#next we will split our taxa data into time bins
taxa_mod <- filter(europe_binned, timebins == "Modern")
taxa_yd <- filter(europe_binned, timebins == "YD")
taxa_lgm <- filter(europe_binned, timebins == "LGM")

# Now we will convert these to spatial points and extract the climate data
## Modern
taxa_mod <- st_as_sf(taxa_mod, coords = c("long", "lat"), crs = proj_data)
taxa_mod_vect <- vect(taxa_mod$geometry)
taxa_mod_clims <- terra::extract(europe_clim_mod, taxa_mod_vect)
taxa_mod <- cbind(taxa_mod, taxa_mod_clims)
corylus_mod <- filter(taxa_mod, variablename == "Corylus")
fagus_mod <- filter(taxa_mod, variablename == "Fagus")
picea_mod <- filter(taxa_mod, variablename == "Picea")

## Younger Dryas
taxa_yd <- st_as_sf(taxa_yd, coords = c("long", "lat"), crs = proj_data)
taxa_yd_vect <- vect(taxa_yd$geometry)
taxa_yd_clims <- terra::extract(europe_clim_yd, taxa_yd_vect)
taxa_yd <- cbind(taxa_yd, taxa_yd_clims)
corylus_yd <- filter(taxa_yd, variablename == "Corylus")
fagus_yd <- filter(taxa_yd, variablename == "Fagus")
picea_yd <- filter(taxa_yd, variablename == "Picea")

## Last Glacial Maximum 
taxa_lgm <- st_as_sf(taxa_lgm, coords = c("long", "lat"), crs = proj_data)
taxa_lgm_vect <- vect(taxa_lgm$geometry)
taxa_lgm_clims <- terra::extract(europe_clim_lgm, taxa_lgm_vect)
taxa_lgm <- cbind(taxa_lgm, taxa_lgm_clims)
corylus_lgm <- filter(taxa_lgm, variablename == "Corylus")
fagus_lgm <- filter(taxa_lgm, variablename == "Fagus")
picea_lgm <- filter(taxa_lgm, variablename == "Picea")



```


### Predicting SDMs {.tabset}
Next we are going to set up the species distribution models


#### Corylus 
```{r corylussdm, message = FALSE, eval = TRUE}
par(mfrow = c(2,3))

corylus_mod_glm <- glm(pollen_percent ~ bio_1 + bio_12, data = corylus_mod)
corylus_mod_glm_predict <- predict(c(europe_clim_mod[["bio_1"]], europe_clim_mod[["bio_12"]]), corylus_mod_glm)
plot(corylus_mod_glm_predict, main = "Predicted Corylus Pollen Percent, Modern")

corylus_yd_glm <- glm(pollen_percent ~ bio_1 + bio_12, data = corylus_yd)
corylus_yd_glm_predict <- predict(c(europe_clim_yd[["bio_1"]], europe_clim_yd[["bio_12"]]), corylus_yd_glm)
plot(corylus_yd_glm_predict, main = "Predicted Corylus Pollen Percent, Younger Dryas")

corylus_lgm_glm <- glm(pollen_percent ~ bio_1 + bio_12, data = corylus_lgm)
corylus_lgm_glm_predict <- predict(c(europe_clim_lgm[["bio_1"]], europe_clim_lgm[["bio_12"]]), corylus_lgm_glm)
plot(corylus_lgm_glm_predict, main = "Predicted Corylus Pollen Percent, LGM")

# Using Presence Only data
corylus_mod_glm <- glm(presence ~ bio_1 + bio_12, data = corylus_mod)
corylus_mod_glm_predict <- predict(c(europe_clim_mod[["bio_1"]], europe_clim_mod[["bio_12"]]), corylus_mod_glm)
plot(corylus_mod_glm_predict, main = "Predicted Corylus Presence, Modern")

corylus_yd_glm <- glm(presence ~ bio_1 + bio_12, data = corylus_yd)
corylus_yd_glm_predict <- predict(c(europe_clim_yd[["bio_1"]], europe_clim_yd[["bio_12"]]), corylus_yd_glm)
plot(corylus_yd_glm_predict, main = "Predicted Corylus Presence, Younger Dryas")

corylus_lgm_glm <- glm(presence ~ bio_1 + bio_12, data = corylus_lgm)
corylus_lgm_glm_predict <- predict(c(europe_clim_lgm[["bio_1"]], europe_clim_lgm[["bio_12"]]), corylus_lgm_glm)
plot(corylus_lgm_glm_predict, main = "Predicted Corylus Presence, LGM")

```

#### Fagus
```{r fagussdm, message = FALSE, eval = TRUE}
par(mfrow = c(1,3))

fagus_mod_glm <- glm(pollen_percent ~ bio_1 + bio_12, data = fagus_mod)
fagus_mod_glm_predict <- predict(c(europe_clim_mod[["bio_1"]], europe_clim_mod[["bio_12"]]), fagus_mod_glm)
plot(fagus_mod_glm_predict, main = "Predicted Fagus Pollen Percentage, Modern")

fagus_yd_glm <- glm(pollen_percent ~ bio_1 + bio_12, data = fagus_yd)
fagus_yd_glm_predict <- predict(c(europe_clim_yd[["bio_1"]], europe_clim_yd[["bio_12"]]), fagus_yd_glm)
plot(fagus_yd_glm_predict, main = "Predicted Fagus Pollen Percentage, Younger Dryas")

fagus_lgm_glm <- glm(pollen_percent ~ bio_1 + bio_12, data = fagus_lgm)
fagus_lgm_glm_predict <- predict(c(europe_clim_lgm[["bio_1"]], europe_clim_lgm[["bio_12"]]), fagus_lgm_glm)
plot(fagus_lgm_glm_predict, main = "Predicted Fagus Pollen Percentage, LGM")

# Using Presence Only data
fagus_mod_glm <- glm(presence ~ bio_1 + bio_12, data = fagus_mod)
fagus_mod_glm_predict <- predict(c(europe_clim_mod[["bio_1"]], europe_clim_mod[["bio_12"]]), fagus_mod_glm)
plot(fagus_mod_glm_predict, main = "Predicted Fagus Presence, Modern")

fagus_yd_glm <- glm(presence ~ bio_1 + bio_12, data = fagus_yd)
fagus_yd_glm_predict <- predict(c(europe_clim_yd[["bio_1"]], europe_clim_yd[["bio_12"]]), fagus_yd_glm)
plot(fagus_yd_glm_predict, main = "Predicted Fagus Presence, Younger Dryas")

fagus_lgm_glm <- glm(presence ~ bio_1 + bio_12, data = fagus_lgm)
fagus_lgm_glm_predict <- predict(c(europe_clim_lgm[["bio_1"]], europe_clim_lgm[["bio_12"]]), fagus_lgm_glm)
plot(fagus_lgm_glm_predict, main = "Predicted Fagus Presence, LGM")

```

#### Picea 
```{r piceasdm, message = FALSE, eval = TRUE}
par(mfrow = c(1,3))

picea_mod_glm <- glm(pollen_percent ~ bio_1 + bio_12, data = picea_mod)
picea_mod_glm_predict <- predict(c(europe_clim_mod[["bio_1"]], europe_clim_mod[["bio_12"]]), picea_mod_glm)
plot(picea_mod_glm_predict, main = "Predicted picea Pollen Percentage, Modern")

picea_yd_glm <- glm(pollen_percent ~ bio_1 + bio_12, data = picea_yd)
picea_yd_glm_predict <- predict(c(europe_clim_yd[["bio_1"]], europe_clim_yd[["bio_12"]]), picea_yd_glm)
plot(picea_yd_glm_predict, main = "Predicted picea Pollen Percentage, Younger Dryas")

picea_lgm_glm <- glm(pollen_percent ~ bio_1 + bio_12, data = picea_lgm)
picea_lgm_glm_predict <- predict(c(europe_clim_lgm[["bio_1"]], europe_clim_lgm[["bio_12"]]), picea_lgm_glm)
plot(picea_lgm_glm_predict, main = "Predicted picea Pollen Percentage, LGM")

# Using Presence Only data
picea_mod_glm <- glm(presence ~ bio_1 + bio_12, data = picea_mod)
picea_mod_glm_predict <- predict(c(europe_clim_mod[["bio_1"]], europe_clim_mod[["bio_12"]]), picea_mod_glm)
plot(picea_mod_glm_predict, main = "Predicted Picea Presence, Modern")

picea_yd_glm <- glm(presence ~ bio_1 + bio_12, data = picea_yd)
picea_yd_glm_predict <- predict(c(europe_clim_yd[["bio_1"]], europe_clim_yd[["bio_12"]]), picea_yd_glm)
plot(picea_yd_glm_predict, main = "Predicted Picea Presence, Younger Dryas")

picea_lgm_glm <- glm(presence ~ bio_1 + bio_12, data = picea_lgm)
picea_lgm_glm_predict <- predict(c(europe_clim_lgm[["bio_1"]], europe_clim_lgm[["bio_12"]]), picea_lgm_glm)
plot(picea_lgm_glm_predict, main = "Predicted Picea Presence, LGM")

```

## Summary

From this notebook we have learned how to:

1.  Download a single record (the monticchio record using `get_downloads()`)
2.  Examining the chronologies for the record (using `chronologies()` and associated chronological controls (using `chroncontrols()`)
3.  Creating a new chronology for the record (using `set_chronology()`)
4.  Adding the chronology to the record (using `add_chronology()`)
5.  Switching between default chronologies (using `set_default()`)

This approach is focused on a single record, but much of what is done here can be extended to multiple records using functions. We hope it's been helpful!
